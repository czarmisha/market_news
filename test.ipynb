{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import schedule\n",
    "import time\n",
    "\n",
    "def test():\n",
    "    print('start1')\n",
    "    time.sleep(70)\n",
    "    print('end1')\n",
    "\n",
    "def test2():\n",
    "    print('end2')\n",
    "\n",
    "schedule.every().day.at(\"14:08\").do(test)\n",
    "schedule.every().day.at(\"14:08\").do(test2)\n",
    "\n",
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "05:00 indexes\n",
    "05:30 monday earnings on week\n",
    "06:00 early earnings\n",
    "07:00 earnings\n",
    "07:28-07:35 RC1\n",
    "07:35-08:10 RC2\n",
    "07:40 CC\n",
    "08:50-09:10 RC2\n",
    "09:00 IPO\n",
    "09:00 lock up\n",
    "offerings ??\n",
    "rc mb1\n",
    "rc mb2\n",
    "13:00 indxch\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "ua = UserAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.iposcoop.com/ipo-calendar/'\n",
    "res = requests.get(url, headers={'User-Agent': ua.chrome})\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "table = soup.find('table', attrs={'class': 'standard-table ipolist'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tbody>\n",
       "<tr class=\"odd\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/lead-real-estate-co-ltd/\">Lead Real Estate Co., Ltd.</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=LRE\" rel=\"nofollow\" target=\"_blank\">LRE</a></td>\n",
       "<td class=\"hide-sm\">EF Hutton</td>\n",
       "<td>1.1</td>\n",
       "<td class=\"hide-sm\">7.00</td>\n",
       "<td class=\"hide-sm\">9.00</td>\n",
       "<td>$ 9.1 mil</td>\n",
       "<td>3/20/2023 Week of</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/u-power-ltd/\">U Power Ltd.</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=UCAR\" rel=\"nofollow\" target=\"_blank\">UCAR</a></td>\n",
       "<td class=\"hide-sm\">AMTD Global Markets/ WestPark Capital</td>\n",
       "<td>2.5</td>\n",
       "<td class=\"hide-sm\">6.00</td>\n",
       "<td class=\"hide-sm\">8.00</td>\n",
       "<td>$ 17.5 mil</td>\n",
       "<td>3/20/2023 Week of</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/golden-heaven-group-ltd/\">Golden Heaven Group Ltd.</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=GDHG\" rel=\"nofollow\" target=\"_blank\">GDHG</a></td>\n",
       "<td class=\"hide-sm\">Revere Securities/ R.F. Lafferty &amp; Co. Inc.</td>\n",
       "<td>2.0</td>\n",
       "<td class=\"hide-sm\">4.00</td>\n",
       "<td class=\"hide-sm\">5.00</td>\n",
       "<td>$ 9.0 mil</td>\n",
       "<td>3/21/2023 Tuesday</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/mangoceuticals/\">Mangoceuticals, Inc.</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=MGRX\" rel=\"nofollow\" target=\"_blank\">MGRX</a></td>\n",
       "<td class=\"hide-sm\">Boustead Securities</td>\n",
       "<td>1.3</td>\n",
       "<td class=\"hide-sm\">4.00</td>\n",
       "<td class=\"hide-sm\">4.00</td>\n",
       "<td>$ 5.0 mil</td>\n",
       "<td>3/21/2023 Tuesday</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/ohmyhome-ltd/\">Ohmyhome Ltd</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=OMH\" rel=\"nofollow\" target=\"_blank\">OMH</a></td>\n",
       "<td class=\"hide-sm\">Prime Number Capital</td>\n",
       "<td>3.3</td>\n",
       "<td class=\"hide-sm\">4.00</td>\n",
       "<td class=\"hide-sm\">5.00</td>\n",
       "<td>$ 14.6 mil</td>\n",
       "<td>3/21/2023 Tuesday</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "<tr class=\"even\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/yangufang-international-group-co-ltd/\">YanGuFang International Group Co., Ltd.</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=YGF\" rel=\"nofollow\" target=\"_blank\">YGF</a></td>\n",
       "<td class=\"hide-sm\">EF Hutton</td>\n",
       "<td>2.5</td>\n",
       "<td class=\"hide-sm\">4.00</td>\n",
       "<td class=\"hide-sm\">6.00</td>\n",
       "<td>$ 12.5 mil</td>\n",
       "<td>3/21/2023 Tuesday</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "<tr class=\"odd\">\n",
       "<td><a href=\"https://www.iposcoop.com/ipo/shengfeng-development-ltd/\">Shengfeng Development Ltd.</a></td>\n",
       "<td><a class=\"externalLink\" href=\"http://finance.yahoo.com/q?s=SFWL\" rel=\"nofollow\" target=\"_blank\">SFWL</a></td>\n",
       "<td class=\"hide-sm\">Univest Securities</td>\n",
       "<td>3.0</td>\n",
       "<td class=\"hide-sm\">4.00</td>\n",
       "<td class=\"hide-sm\">5.00</td>\n",
       "<td>$ 13.5 mil</td>\n",
       "<td>3/23/2023 Thursday</td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "<td><a href=\"https://www.iposcoop.com/how-to-subscribe\">S/O</a></td>\n",
       "</tr>\n",
       "</tbody>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.tbody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-18 00:00:00 2023-03-20 00:00:00\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for row in table.tbody.find_all('tr'):\n",
    "    date = datetime.datetime.strptime(row.find_all('td')[7].get_text().split(' ')[0], '%m/%d/%Y')\n",
    "    today = datetime.datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "    print(today, date)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_html(str(table))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 Lead Real Estate Co., Ltd.\n",
       "1                               U Power Ltd.\n",
       "2                   Golden Heaven Group Ltd.\n",
       "3                       Mangoceuticals, Inc.\n",
       "4                               Ohmyhome Ltd\n",
       "5    YanGuFang International Group Co., Ltd.\n",
       "6                 Shengfeng Development Ltd.\n",
       "Name: Company, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0].Company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lxml\n",
      "  Downloading lxml-4.9.2-cp310-cp310-macosx_10_15_x86_64.whl (4.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "Successfully installed lxml-4.9.2\n"
     ]
    }
   ],
   "source": [
    "!pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_html(\u001b[39mstr\u001b[39;49m(soup), attrs\u001b[39m=\u001b[39;49m{\u001b[39m'\u001b[39;49m\u001b[39mclass\u001b[39;49m\u001b[39m'\u001b[39;49m: \u001b[39m'\u001b[39;49m\u001b[39mstasndard-table ipolist\u001b[39;49m\u001b[39m'\u001b[39;49m})\n\u001b[1;32m      2\u001b[0m df2\n",
      "File \u001b[0;32m~/Desktop/LEXX/market_news/venv/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/LEXX/market_news/venv/lib/python3.10/site-packages/pandas/io/html.py:1205\u001b[0m, in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only, extract_links)\u001b[0m\n\u001b[1;32m   1201\u001b[0m validate_header_arg(header)\n\u001b[1;32m   1203\u001b[0m io \u001b[39m=\u001b[39m stringify_path(io)\n\u001b[0;32m-> 1205\u001b[0m \u001b[39mreturn\u001b[39;00m _parse(\n\u001b[1;32m   1206\u001b[0m     flavor\u001b[39m=\u001b[39;49mflavor,\n\u001b[1;32m   1207\u001b[0m     io\u001b[39m=\u001b[39;49mio,\n\u001b[1;32m   1208\u001b[0m     match\u001b[39m=\u001b[39;49mmatch,\n\u001b[1;32m   1209\u001b[0m     header\u001b[39m=\u001b[39;49mheader,\n\u001b[1;32m   1210\u001b[0m     index_col\u001b[39m=\u001b[39;49mindex_col,\n\u001b[1;32m   1211\u001b[0m     skiprows\u001b[39m=\u001b[39;49mskiprows,\n\u001b[1;32m   1212\u001b[0m     parse_dates\u001b[39m=\u001b[39;49mparse_dates,\n\u001b[1;32m   1213\u001b[0m     thousands\u001b[39m=\u001b[39;49mthousands,\n\u001b[1;32m   1214\u001b[0m     attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1215\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   1216\u001b[0m     decimal\u001b[39m=\u001b[39;49mdecimal,\n\u001b[1;32m   1217\u001b[0m     converters\u001b[39m=\u001b[39;49mconverters,\n\u001b[1;32m   1218\u001b[0m     na_values\u001b[39m=\u001b[39;49mna_values,\n\u001b[1;32m   1219\u001b[0m     keep_default_na\u001b[39m=\u001b[39;49mkeep_default_na,\n\u001b[1;32m   1220\u001b[0m     displayed_only\u001b[39m=\u001b[39;49mdisplayed_only,\n\u001b[1;32m   1221\u001b[0m     extract_links\u001b[39m=\u001b[39;49mextract_links,\n\u001b[1;32m   1222\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/LEXX/market_news/venv/lib/python3.10/site-packages/pandas/io/html.py:1006\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m     \u001b[39massert\u001b[39;00m retained \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m  \u001b[39m# for mypy\u001b[39;00m\n\u001b[0;32m-> 1006\u001b[0m     \u001b[39mraise\u001b[39;00m retained\n\u001b[1;32m   1008\u001b[0m ret \u001b[39m=\u001b[39m []\n\u001b[1;32m   1009\u001b[0m \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables:\n",
      "File \u001b[0;32m~/Desktop/LEXX/market_news/venv/lib/python3.10/site-packages/pandas/io/html.py:986\u001b[0m, in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, extract_links, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m p \u001b[39m=\u001b[39m parser(io, compiled_match, attrs, encoding, displayed_only, extract_links)\n\u001b[1;32m    985\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 986\u001b[0m     tables \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mparse_tables()\n\u001b[1;32m    987\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m caught:\n\u001b[1;32m    988\u001b[0m     \u001b[39m# if `io` is an io-like object, check if it's seekable\u001b[39;00m\n\u001b[1;32m    989\u001b[0m     \u001b[39m# and try to rewind it before trying the next parser\u001b[39;00m\n\u001b[1;32m    990\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(io, \u001b[39m\"\u001b[39m\u001b[39mseekable\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m io\u001b[39m.\u001b[39mseekable():\n",
      "File \u001b[0;32m~/Desktop/LEXX/market_news/venv/lib/python3.10/site-packages/pandas/io/html.py:262\u001b[0m, in \u001b[0;36m_HtmlFrameParser.parse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse_tables\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    255\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[39m    Parse and return all tables from the DOM.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[39m    list of parsed (header, body, footer) tuples from tables.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 262\u001b[0m     tables \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse_tables(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_doc(), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmatch, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattrs)\n\u001b[1;32m    263\u001b[0m     \u001b[39mreturn\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parse_thead_tbody_tfoot(table) \u001b[39mfor\u001b[39;00m table \u001b[39min\u001b[39;00m tables)\n",
      "File \u001b[0;32m~/Desktop/LEXX/market_news/venv/lib/python3.10/site-packages/pandas/io/html.py:618\u001b[0m, in \u001b[0;36m_BeautifulSoupHtml5LibFrameParser._parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    615\u001b[0m tables \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39mfind_all(element_name, attrs\u001b[39m=\u001b[39mattrs)\n\u001b[1;32m    617\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tables:\n\u001b[0;32m--> 618\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo tables found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    620\u001b[0m result \u001b[39m=\u001b[39m []\n\u001b[1;32m    621\u001b[0m unique_tables \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "df2 = pd.read_html(str(soup), attrs={'class': 'stasndard-table ipolist'})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting html5lib\n",
      "  Using cached html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Requirement already satisfied: six>=1.9 in ./venv/lib/python3.10/site-packages (from html5lib) (1.16.0)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Installing collected packages: webencodings, html5lib\n",
      "Successfully installed html5lib-1.1 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install html5lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.iposcoop.com/ipo/lead-real-estate-co-ltd/'\n",
    "res = requests.get(url, headers={'User-Agent': ua.chrome})\n",
    "soup = BeautifulSoup(res.content, 'html.parser')\n",
    "table = soup.find('table', attrs={'class': 'ipo-table'})\n",
    "rows = table.find_all('tr')\n",
    "rows[11].find_all('td')[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "now.weekday()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = yf.Ticker('lase').history(start='2022-09-30', end='2022-10-01', interval='1d').reset_index()\n",
    "# yf.Ticker('lase').history(period='max', interval='1d').reset_index()\n",
    "# a = yf.Ticker('aapl').history(start='2023-03-19', end='2023-03-19', interval='1d').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Stock Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-09-30 00:00:00-04:00</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.56</td>\n",
       "      <td>2.58</td>\n",
       "      <td>7078100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Date  Open  High   Low  Close   Volume  Dividends  \\\n",
       "0 2022-09-30 00:00:00-04:00   5.0   5.5  2.56   2.58  7078100        0.0   \n",
       "\n",
       "   Stock Splits  \n",
       "0           0.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "date = datetime.datetime.strptime('2022-09-30', '%Y-%m-%d')\n",
    "date2 = pd.Timestamp('2022-09-30')\n",
    "a[a.Date == '2022-09-30'].Open[0]\n",
    "# print(date, date2)\n",
    "# print(type(a.iloc[0].Date))\n",
    "# print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "yfinance failed to decrypt Yahoo data response",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m yf\u001b[39m.\u001b[39;49mTicker(\u001b[39m'\u001b[39;49m\u001b[39mAMV\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49minfo\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\ticker.py:138\u001b[0m, in \u001b[0;36mTicker.info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m    137\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfo\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_info()\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\base.py:1475\u001b[0m, in \u001b[0;36mTickerBase.get_info\u001b[1;34m(self, proxy)\u001b[0m\n\u001b[0;32m   1473\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_info\u001b[39m(\u001b[39mself\u001b[39m, proxy\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m   1474\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_quote\u001b[39m.\u001b[39mproxy \u001b[39m=\u001b[39m proxy\n\u001b[1;32m-> 1475\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_quote\u001b[39m.\u001b[39;49minfo\n\u001b[0;32m   1476\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\scrapers\\quote.py:95\u001b[0m, in \u001b[0;36mQuote.info\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39m@property\u001b[39m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minfo\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m:\n\u001b[0;32m     94\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_scrape(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproxy)\n\u001b[0;32m     96\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_scrape_complementary(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproxy)\n\u001b[0;32m     98\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_info\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\scrapers\\quote.py:124\u001b[0m, in \u001b[0;36mQuote._scrape\u001b[1;34m(self, proxy)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_already_scraped \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[39m# get info and sustainability\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m json_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data\u001b[39m.\u001b[39;49mget_json_data_stores(proxy\u001b[39m=\u001b[39;49mproxy)\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     quote_summary_store \u001b[39m=\u001b[39m json_data[\u001b[39m'\u001b[39m\u001b[39mQuoteSummaryStore\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\data.py:41\u001b[0m, in \u001b[0;36mlru_cache_freezeargs.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m args \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m([\u001b[39mtuple\u001b[39m(arg) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arg, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args])\n\u001b[0;32m     40\u001b[0m kwargs \u001b[39m=\u001b[39m {k: \u001b[39mtuple\u001b[39m(v) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(v, \u001b[39mlist\u001b[39m) \u001b[39melse\u001b[39;00m v \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m kwargs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m---> 41\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\data.py:311\u001b[0m, in \u001b[0;36mTickerData.get_json_data_stores\u001b[1;34m(self, sub_page, proxy)\u001b[0m\n\u001b[0;32m    308\u001b[0m     keys \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m response_gh\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39msplitlines()\n\u001b[0;32m    310\u001b[0m \u001b[39m# Decrypt!\u001b[39;00m\n\u001b[1;32m--> 311\u001b[0m stores \u001b[39m=\u001b[39m decrypt_cryptojs_aes_stores(data, keys)\n\u001b[0;32m    312\u001b[0m \u001b[39mif\u001b[39;00m stores \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     \u001b[39m# Maybe Yahoo returned old format, not encrypted\u001b[39;00m\n\u001b[0;32m    314\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m data \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mdispatcher\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m data[\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\yfinance\\data.py:162\u001b[0m, in \u001b[0;36mdecrypt_cryptojs_aes_stores\u001b[1;34m(data, keys)\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m success:\n\u001b[1;32m--> 162\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39myfinance failed to decrypt Yahoo data response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    164\u001b[0m decoded_stores \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mloads(plaintext)\n\u001b[0;32m    165\u001b[0m \u001b[39mreturn\u001b[39;00m decoded_stores\n",
      "\u001b[1;31mException\u001b[0m: yfinance failed to decrypt Yahoo data response"
     ]
    }
   ],
   "source": [
    "yf.Ticker('AMV').info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fake_useragent import UserAgent\n",
    "ua = UserAgent()\n",
    "def create_soup(url, params=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    res = requests.get(url, headers={'User-Agent': ua.chrome}, params=params) # запрос по url.\n",
    "    # всегда при удачном запросе в ответе будет 200й статус\n",
    "    if not res.status_code == 200:\n",
    "        print('!!! status code is not OK !!!')\n",
    "        return None\n",
    "    # BeautifulSoup парсит html документ в читабельный вид и позволяет гибко с ним работать\n",
    "    # res.content то что мы получили от сервера, в нашем случае строку с html кодом страницы по url\n",
    "    return BeautifulSoup(res.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.marketbeat.com/ipos/lockup-expirations/'\n",
    "soup = create_soup(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table')\n",
    "row = table.tbody.find_all('tr')[0]\n",
    "row_columns = row.find_all('td')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AMV'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_columns[0].find('div', attrs={'class': 'ticker-area'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://finviz.com/quote.ashx'\n",
    "soup = create_soup(url2, {'t': 'AMV'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.40M'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcap_td = soup.find('td', string='Market Cap')\n",
    "mcap_td.next.next.textABBV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Friday'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.strptime('2023-03-24', '%Y-%m-%d').strftime('%A')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lockup_data = {\n",
    "    'Monday': [],\n",
    "    'Tuesday' : [],\n",
    "    'Wednesday' : [],\n",
    "    'Thursday' : [],\n",
    "    'Friday' : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Monday': [], 'Tuesday': [], 'Wednesday': [], 'Thursday': [], 'Friday': []}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "week = ['2023-03-20', '2023-03-21', '2023-03-22', '2023-03-23', '2023-03-24']\n",
    "lockup_data2 = {datetime.datetime.strptime(day, '%Y-%m-%d').strftime('%A'): [] for day in week}\n",
    "lockup_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(float('5.00'), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "\n",
    "options = FirefoxOptions()\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.set_window_size(1500, 1200)\n",
    "driver.get('https://www.briefing.com/InPlayEq/Search/ticker.htm?ticker=calls&range=6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ipo', '']\n"
     ]
    }
   ],
   "source": [
    "with open('progress.txt', 'r') as file:\n",
    "    row = file.read().split(',')\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20-Mar-23', '', '09:07', 'ET']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'20-Mar-23  09:07 ET'.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20-Mar-23'"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datetime.datetime.now().strftime('%d-%b-%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "\n",
    "# from config import urls\n",
    "\n",
    "\n",
    "options = FirefoxOptions()\n",
    "driver = webdriver.Firefox(options=options)\n",
    "driver.set_window_size(1500, 1200)\n",
    "driver.get('https://www.briefing.com')\n",
    "\n",
    "\n",
    "class BriefingParser:\n",
    "    def __init__(self, url_string):\n",
    "        self.target_url = 'https://www.briefing.com/InPlayEq/InPlay/InPlay.htm'\n",
    "        self.driver = driver\n",
    "        self.html_text, self.soup = '', ''\n",
    "        self.get_html_text()\n",
    "        self.target_url = url_string\n",
    "        self.get_html_text()\n",
    "        self.get_soup()\n",
    "\n",
    "    def set_new_url(self, new_url):\n",
    "        self.target_url = new_url\n",
    "        self.get_html_text()\n",
    "        self.get_soup()\n",
    "\n",
    "    def get_html_text(self):\n",
    "        self.driver.get(self.target_url)\n",
    "        time.sleep(5)\n",
    "        self.html_text = self.driver.execute_script(\"return document.getElementsByTagName('html')[0].innerHTML\")\n",
    "\n",
    "    def get_soup(self):\n",
    "        self.soup = BeautifulSoup(self.html_text, \"html.parser\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Research calls ****\n",
      "False False False\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'r_calls_progress.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 78\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[39mprint\u001b[39m(output)\n\u001b[0;32m     76\u001b[0m     \u001b[39mprint\u001b[39m(call_1, call_2, call_3)\n\u001b[1;32m---> 78\u001b[0m main()\n",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m call_number \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(call_1, call_2, call_3)\n\u001b[1;32m---> 12\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mr_calls_progress.txt\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m     13\u001b[0m     progress \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m     \u001b[39mprint\u001b[39m(progress)\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\projects\\market_news\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py:282\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[39mif\u001b[39;00m file \u001b[39min\u001b[39;00m {\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m}:\n\u001b[0;32m    276\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    277\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIPython won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt let you open fd=\u001b[39m\u001b[39m{\u001b[39;00mfile\u001b[39m}\u001b[39;00m\u001b[39m by default \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    278\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    279\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39myou can use builtins\u001b[39m\u001b[39m'\u001b[39m\u001b[39m open.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    280\u001b[0m     )\n\u001b[1;32m--> 282\u001b[0m \u001b[39mreturn\u001b[39;00m io_open(file, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'r_calls_progress.txt'"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# from utils import briefing\n",
    "# from config import urls\n",
    "\n",
    "def main():\n",
    "    print('**** Research calls ****')\n",
    "    call_1, call_2, call_3 = False, False, False\n",
    "    call_number = None\n",
    "\n",
    "    print(call_1, call_2, call_3)\n",
    "    with open('r_calls_progress.txt') as file:\n",
    "        progress = file.read().split(',')\n",
    "        print(progress)\n",
    "\n",
    "    if not call_1 and not 'call_1' in progress:\n",
    "        print('call1')\n",
    "        call_1 = True\n",
    "        call_number = ''\n",
    "    elif not call_2 and not 'call_2' in progress:\n",
    "        print('call2')\n",
    "        call_1 = True\n",
    "        call_2 = True\n",
    "        call_number = 'II'\n",
    "    elif not call_3 and not 'call_3' in progress:\n",
    "        print('call3')\n",
    "        call_1 = True\n",
    "        call_2 = True\n",
    "        call_3 = True\n",
    "        call_number = 'III'\n",
    "    \n",
    "    if call_number is None:\n",
    "        print('!!! error call_number !!!')\n",
    "        return \n",
    "\n",
    "    output = f'Research Calls {call_number}'.strip()\n",
    "    \n",
    "    parser = BriefingParser('https://www.briefing.com/InPlayEq/Search/ticker.htm?ticker=calls&range=6')\n",
    "    soup = parser.soup\n",
    "    rows = soup.find_all('tr', class_='inplayRow')\n",
    "    today = datetime.datetime.now().strftime('%d-%b-%y')\n",
    "\n",
    "    for row in rows:\n",
    "        row_date = row.find('span', attrs={'id': 'ArticleTime'}).text.split(' ')[0]\n",
    "        if not row_date == today:\n",
    "            return\n",
    "        \n",
    "        row_title = row.find('td', attrs={'class': 'articleColumn'}).find('div', attrs={'class': 'lip-title'}).text\n",
    "        if not row_title == output:\n",
    "            continue\n",
    "        output += '\\n'\n",
    "\n",
    "        row_text = row.find('td', attrs={'class': 'articleColumn'}).find('div', attrs={'class': 'lip-article'}).find('ul')\n",
    "        tmp = ''\n",
    "        for li in row_text.find_all('li'):\n",
    "            if li.text.split(':')[0] in ['Upgrades', 'Downgrades', 'Others']:\n",
    "                tmp += f\"\\n{li.text.split(':')[0]}\\n\"\n",
    "                continue\n",
    "            \n",
    "            tmp += f\"{li.text.split(':')[0]}\\n\"\n",
    "        \n",
    "        with open('r_calls_progress.txt', 'a') as file:\n",
    "            to_write = 'call_1'\n",
    "            if call_number == 'II':\n",
    "                to_write = 'call_2'\n",
    "            elif call_number == 'III':\n",
    "                to_write = 'call_3'\n",
    "\n",
    "            print('to write', to_write)\n",
    "            file.write(to_write + ',')\n",
    "        \n",
    "        output += tmp + '\\n'\n",
    "        break\n",
    "\n",
    "    print(output)\n",
    "    print(call_1, call_2, call_3)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Upgrades', 'Assurant (AIZ) upgraded to Outperform from Mkt Perform at Keefe Bruyette; tgt $52Emerson (EMR) upgraded to Overweight from Equal-Weight at Morgan Stanley; tgt raised to $96FleetCor (FLT) upgraded to Outperform from Mkt Perform at Raymond James; tgt $254Harley-Davidson (HOG) upgraded to Overweight from Equal-Weight at Morgan Stanley; tgt $50Imperial Oil (IMO) upgraded to Sector Outperform from Sector Perform at ScotiabankMeta Platforms (META) upgraded to Overweight from Equal-Weight at Morgan Stanley; tgt raised to $250Wix.com (WIX) upgraded to Overweight from Neutral at Piper Sandler; tgt raised to $120']\n",
      "['Assurant (AIZ) upgraded to Outperform from Mkt Perform at Keefe Bruyette; tgt $52']\n",
      "['Emerson (EMR) upgraded to Overweight from Equal-Weight at Morgan Stanley; tgt raised to $96']\n",
      "['FleetCor (FLT) upgraded to Outperform from Mkt Perform at Raymond James; tgt $254']\n",
      "['Harley-Davidson (HOG) upgraded to Overweight from Equal-Weight at Morgan Stanley; tgt $50']\n",
      "['Imperial Oil (IMO) upgraded to Sector Outperform from Sector Perform at Scotiabank']\n",
      "['Meta Platforms (META) upgraded to Overweight from Equal-Weight at Morgan Stanley; tgt raised to $250']\n",
      "['Wix.com (WIX) upgraded to Overweight from Neutral at Piper Sandler; tgt raised to $120']\n",
      "['Downgrades', 'Agree Realty (ADC) downgraded to Mkt Perform from Mkt Outperform at JMP SecuritiesGoDaddy (GDDY) downgraded to Neutral from Overweight at Piper Sandler; tgt lowered to $88']\n",
      "['Agree Realty (ADC) downgraded to Mkt Perform from Mkt Outperform at JMP Securities']\n",
      "['GoDaddy (GDDY) downgraded to Neutral from Overweight at Piper Sandler; tgt lowered to $88']\n",
      "['Others', 'Allogene (ALLO) initiated with a Mkt Perform at Bernstein; tgt $6Alnylam Pharma (ALNY) initiated with an Outperform at Bernstein; tgt $243Arrowhead (ARWR) initiated with a Mkt Perform at Bernstein; tgt $27Beam Therapeutics (BEAM) initiated with a Mkt Perform at Bernstein; tgt $37BioMarin Pharmaceutical (BMRN) initiated with an Underperform at Bernstein; tgt $81CRISPR Therapeutics (CRSP) initiated with a Mkt Perform at Bernstein; tgt $44Intellia Therapeutics (NTLA) initiated with an Outperform at Bernstein; tgt $54Ionis Pharma (IONS) initiated with an Underperform at Bernstein; tgt $31Vertex Pharma (VRTX) initiated with an Outperform at Bernstein; tgt $344']\n",
      "['Allogene (ALLO) initiated with a Mkt Perform at Bernstein; tgt $6']\n",
      "['Alnylam Pharma (ALNY) initiated with an Outperform at Bernstein; tgt $243']\n",
      "['Arrowhead (ARWR) initiated with a Mkt Perform at Bernstein; tgt $27']\n",
      "['Beam Therapeutics (BEAM) initiated with a Mkt Perform at Bernstein; tgt $37']\n",
      "['BioMarin Pharmaceutical (BMRN) initiated with an Underperform at Bernstein; tgt $81']\n",
      "['CRISPR Therapeutics (CRSP) initiated with a Mkt Perform at Bernstein; tgt $44']\n",
      "['Intellia Therapeutics (NTLA) initiated with an Outperform at Bernstein; tgt $54']\n",
      "['Ionis Pharma (IONS) initiated with an Underperform at Bernstein; tgt $31']\n",
      "['Vertex Pharma (VRTX) initiated with an Outperform at Bernstein; tgt $344']\n"
     ]
    }
   ],
   "source": [
    "for li in row_text.find_all('li'):\n",
    "    print(li.text.split(':'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
